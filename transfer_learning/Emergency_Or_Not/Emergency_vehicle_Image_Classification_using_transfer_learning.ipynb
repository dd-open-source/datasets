{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ad2550d9",
      "metadata": {},
      "source": [
        "This is our solution for [Analytics Vidhya Hackathon](https://datahack.analyticsvidhya.com/contest/janatahack-computer-vision-hackathon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "KUXK8UUbFB-0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUXK8UUbFB-0",
        "outputId": "3039cd3c-d103-44b6-efa5-773493548308"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Comment this if you are not running in colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed90508d-fc4b-49bb-a2a6-6bdb6e8f1f7d",
      "metadata": {
        "id": "ed90508d-fc4b-49bb-a2a6-6bdb6e8f1f7d"
      },
      "source": [
        "### Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "83f2a0ad-05e3-41b9-b988-c7b4ca1ac58d",
      "metadata": {
        "id": "83f2a0ad-05e3-41b9-b988-c7b4ca1ac58d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from os import path, listdir\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import mobilenet_v2\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a0cbc01-1eeb-4513-862a-abd3acd1d239",
      "metadata": {
        "id": "8a0cbc01-1eeb-4513-862a-abd3acd1d239"
      },
      "source": [
        "### Defines reusable constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "18f79ffb-291a-4d83-a0d0-3395220a0a5a",
      "metadata": {
        "id": "18f79ffb-291a-4d83-a0d0-3395220a0a5a"
      },
      "outputs": [],
      "source": [
        "# Data files: \n",
        "# Google drive: https://drive.google.com/file/d/1Ylz6tmeSjxwg489bs_XZI-kCG9TxQ3mN/view or\n",
        "# Github: https://github.com/dd-open-source/ml-projects/blob/main/transfer_learning/data.zip\n",
        "# Download the above data files from either our google drive or github \n",
        "# to your google drive or local computer and update the below paths accordingly\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/ML_Projects/Emergency_Or_Not/data\"\n",
        "models_path = \"/content/drive/MyDrive/ML_Projects/Emergency_Or_Not/models\"\n",
        "train_csv_path = path.join(data_path, 'train.csv')\n",
        "test_csv_path = path.join(data_path, 'test.csv')\n",
        "label_col = 'emergency_or_not'\n",
        "image_idx_col = 'image_idx'\n",
        "image_names_col = 'image_names'\n",
        "images_dir = path.join(data_path, \"images\")\n",
        "imgx = 128\n",
        "imgy = 128\n",
        "images_npy_file = path.join(data_path, 'images_{}x{}.npy'.format(imgx, imgy))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "u99lkGs6bPcS",
      "metadata": {
        "id": "u99lkGs6bPcS"
      },
      "source": [
        "Define common functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "71b0f60f-e709-4932-958f-e90f930771ed",
      "metadata": {
        "id": "71b0f60f-e709-4932-958f-e90f930771ed"
      },
      "outputs": [],
      "source": [
        "def get_image_id(img_name):\n",
        "    return int(img_name[:-4])\n",
        "\n",
        "def get_image(img_name):\n",
        "    img_path = path.join(images_dir, img_name)\n",
        "    return Image.open(img_path)\n",
        "\n",
        "# Shows a randomly selected image from data\n",
        "def showImage(df):\n",
        "    sample = df.sample(n=1).iloc[0]\n",
        "    img = get_image(sample[image_names_col])\n",
        "    plt.title(sample[target_col])\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "# Saves images as numpy array for faster training cycles\n",
        "def save_images_as_numpy_array(images_dir=images_dir, newx=imgx, newy=imgy):\n",
        "    if path.exists(images_npy_file):\n",
        "      print(\"File exists so skipping\")\n",
        "      return\n",
        "    files = listdir(images_dir)\n",
        "    images_arr = np.zeros((len(files), newx, newy, 3))\n",
        "    for fname in files:\n",
        "        img = get_image(fname)\n",
        "        img_id = get_image_id(fname)\n",
        "        images_arr[img_id] = np.array(img.resize((newx, newy))).astype(np.uint8)\n",
        "    with open(images_npy_file, 'wb') as f:\n",
        "        np.save(f, images_arr)\n",
        "\n",
        "# Creates tensorflow dataset for images\n",
        "def create_image_dataset(df):\n",
        "    def extract_image(img_id):\n",
        "        return tf.cast(all_images_tensor[img_id]/255, tf.float32)\n",
        "    \n",
        "    ds = tf.data.Dataset.from_tensor_slices(df[image_idx_col].values)\n",
        "    ds = ds.map(extract_image)\n",
        "    return ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Creates tensorflow dataset for images and their labels\n",
        "def create_dataset_with_labels(df):\n",
        "    img_ds = create_image_dataset(df)\n",
        "    labels_ds = tf.data.Dataset.from_tensor_slices(df[label_col].values)\n",
        "    return tf.data.Dataset.zip((img_ds, labels_ds)).batch(32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "G7B8mwVfaSX4",
      "metadata": {
        "id": "G7B8mwVfaSX4"
      },
      "source": [
        "Generate npy files of all images after resizing to given (imgx, imgy) dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "0a8bf786-dc5a-48dc-a402-9046d6e1946f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a8bf786-dc5a-48dc-a402-9046d6e1946f",
        "outputId": "d9f404fc-0bde-419d-afd6-b1d0c7a36704"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File exists so skipping\n"
          ]
        }
      ],
      "source": [
        "save_images_as_numpy_array()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f252b070-3d27-46c2-ba53-19efb38a1225",
      "metadata": {
        "id": "f252b070-3d27-46c2-ba53-19efb38a1225"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "16cf4fc2-4e03-43c1-a63a-a933a657d232",
      "metadata": {
        "id": "16cf4fc2-4e03-43c1-a63a-a933a657d232"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(train_csv_path)\n",
        "test_df = pd.read_csv(test_csv_path)\n",
        "with open(images_npy_file, 'rb') as f:\n",
        "    all_images_tensor = tf.constant(np.load(f))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a3a1a38-761b-473d-a917-a223fab1b3e8",
      "metadata": {
        "id": "2a3a1a38-761b-473d-a917-a223fab1b3e8"
      },
      "source": [
        "### Prepare datasets for training and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "4cd6166d-071b-40f0-9426-18dea7dbd83c",
      "metadata": {
        "id": "4cd6166d-071b-40f0-9426-18dea7dbd83c"
      },
      "outputs": [],
      "source": [
        "train_data, val_data = train_test_split(train_df, test_size=0.2)\n",
        "train_ds = create_dataset_with_labels(train_data)\n",
        "val_ds = create_dataset_with_labels(val_data)\n",
        "test_ds = create_image_dataset(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b52dd1fc-b09d-4bd8-be6d-7b54a75804d5",
      "metadata": {
        "id": "b52dd1fc-b09d-4bd8-be6d-7b54a75804d5"
      },
      "source": [
        "### Training deep neaural network using Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JL4feRv_bp2b",
      "metadata": {
        "id": "JL4feRv_bp2b"
      },
      "source": [
        "**Transfer learning**: We are using MobileNet model for image classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "aa2b2db3-253b-47ed-b05a-d6e55a6b5996",
      "metadata": {
        "id": "aa2b2db3-253b-47ed-b05a-d6e55a6b5996"
      },
      "outputs": [],
      "source": [
        "mnet = mobilenet_v2.MobileNetV2(include_top=False, pooling='max', \n",
        "                                weights='imagenet', input_shape=(imgy, imgx, 3))\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        mnet,\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(1, activation=\"sigmoid\")\n",
        "    ])\n",
        "    model.layers[0].trainable=False\n",
        "    return model\n",
        "\n",
        "def compile_and_fit(model, train_ds, val_ds, model_path, epochs=5, patience=3):\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=patience, mode='max')\n",
        "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau( monitor='val_accuracy', factor=0.1, patience=patience,\n",
        "                                                     mode='max', min_delta=0.0001, cooldown=0, min_lr=0.0001)\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=model_path, monitor='val_accuracy',\n",
        "                                                                   mode='max', save_weights_only=True,\n",
        "                                                                   save_best_only=True)\n",
        "    \n",
        "    model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"],\n",
        "                  optimizer=tf.keras.optimizers.Adamax(learning_rate=0.01))\n",
        "    return model.fit(train_ds, epochs=epochs, validation_data=val_ds,\n",
        "                      callbacks=[early_stopping, model_checkpoint_callback, reduce_lr])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "0da91eae-f124-49f2-bd87-c58c858ef2b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0da91eae-f124-49f2-bd87-c58c858ef2b2",
        "outputId": "c89656a0-82d1-4bd5-82ab-7dd19eeba751"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_128 (Funct  (None, 1280)             2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 1281      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,259,265\n",
            "Trainable params: 1,281\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "42/42 [==============================] - 6s 73ms/step - loss: 0.3727 - accuracy: 0.8495 - val_loss: 0.2607 - val_accuracy: 0.9091 - lr: 0.0100\n",
            "Epoch 2/30\n",
            "42/42 [==============================] - 2s 50ms/step - loss: 0.2451 - accuracy: 0.9020 - val_loss: 0.2359 - val_accuracy: 0.9182 - lr: 0.0100\n",
            "Epoch 3/30\n",
            "42/42 [==============================] - 2s 52ms/step - loss: 0.2177 - accuracy: 0.9134 - val_loss: 0.2258 - val_accuracy: 0.9273 - lr: 0.0100\n",
            "Epoch 4/30\n",
            "42/42 [==============================] - 2s 43ms/step - loss: 0.1960 - accuracy: 0.9202 - val_loss: 0.2240 - val_accuracy: 0.9182 - lr: 0.0100\n",
            "Epoch 5/30\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 0.1817 - accuracy: 0.9278 - val_loss: 0.2222 - val_accuracy: 0.9212 - lr: 0.0100\n",
            "Epoch 6/30\n",
            "42/42 [==============================] - 2s 43ms/step - loss: 0.1687 - accuracy: 0.9377 - val_loss: 0.2245 - val_accuracy: 0.9152 - lr: 0.0100\n",
            "Epoch 7/30\n",
            "42/42 [==============================] - 2s 46ms/step - loss: 0.1697 - accuracy: 0.9369 - val_loss: 0.2262 - val_accuracy: 0.9091 - lr: 0.0100\n",
            "Epoch 8/30\n",
            "42/42 [==============================] - 2s 48ms/step - loss: 0.1708 - accuracy: 0.9316 - val_loss: 0.2189 - val_accuracy: 0.9152 - lr: 0.0100\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f713c7fee50>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = create_model()\n",
        "print(model.summary())\n",
        "models_dir = path.join(models_path, \"base\")\n",
        "model_path = path.join(models_dir, \"best\")\n",
        "# model.load_weights(tf.train.latest_checkpoint(models_dir))\n",
        "compile_and_fit(model, train_ds, val_ds, model_path, epochs=30, patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "2d7ffe84-3479-4298-9b5f-cec0cf378dae",
      "metadata": {
        "id": "2d7ffe84-3479-4298-9b5f-cec0cf378dae"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Image_Classification_using_transfer_learrning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
